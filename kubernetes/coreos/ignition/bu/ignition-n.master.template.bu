# https://github.com/coreos/butane/blob/main/docs/config-fcos-v1_1.md
# master
variant: fcos
version: 1.3.0
ignition:
  config:
    merge:
      - source: http://{{SERVER_HOST}}:8080/ignition/merge-common.ign
      - source: http://{{SERVER_HOST}}:8080/ignition/crictl.ign
      - source: http://{{SERVER_HOST}}:8080/ignition/docker.ign
      - source: http://{{SERVER_HOST}}:8080/ignition/etcd.ign
      - source: http://{{SERVER_HOST}}:8080/ignition/kube-apiserver.ign
      - source: http://{{SERVER_HOST}}:8080/ignition/cri-containerd.ign
      - source: http://{{SERVER_HOST}}:8080/ignition/kube-controller-manager.ign
      - source: http://{{SERVER_HOST}}:8080/ignition/kube-nginx.ign
      - source: http://{{SERVER_HOST}}:8080/ignition/kube-proxy.ign
      - source: http://{{SERVER_HOST}}:8080/ignition/kube-scheduler.ign
      - source: http://{{SERVER_HOST}}:8080/ignition/kubelet.ign
passwd:
  users:
    - name: core
      # password_hash: "$1$nwU7Pa6U$zEYWwaz2b/PIv2K.hNu41/"
      # https://github.com/coreos/container-linux-config-transpiler/blob/master/doc/examples.md#generating-a-password-hash
      # $ openssl passwd -1
      ssh_authorized_keys:
        - ssh-rsa {{SSH_PUB}}
      groups:
        - wheel
        - sudo
        - docker
    - name: k8s
      ssh_authorized_keys:
        - ssh-rsa {{SSH_PUB}}
      groups:
        - wheel
        - sudo
        - docker
      home_dir: /home/k8s
systemd:
  units:
    - name: etcd.service
      enabled: true
      contents: |
        [Unit]
        Description=etcd
        Documentation=https://github.com/etcd-io/etcd
        # Requires= 当前 unit 依赖的
        Wants=network-online.target network.target
        # 我在谁之后启动
        After=network-online.target
        # Befora 我在谁之前启动
        # Conflicts 冲突
        # Condition...：当前 Unit 运行必须满足的条件，否则不会运行
        # Assert...：当前 Unit 运行必须满足的条件，否则会报启动失败
        After=network-online.target
        Wants=network-online.target

        [Service]

        # Type=notify
        Restart=on-failure
        # always（总是重启）、on-success、on-failure、on-abnormal、on-abort、on-watchdog
        RestartSec=10s
        # 自动重启当前服务间隔的秒数
        TimeoutStartSec=0
        # 设置该服务允许的最大启动时长
        # LimitNOFILE=40000

        Environment="ETCD_DATA_DIR=/var/lib/etcd"
        Environment="K8S_ROOT=${K8S_ROOT}"

        ExecStartPre=-/usr/bin/mkdir --parents /opt/k8s/var/lib/etcd
        ExecStartPre=-/usr/bin/env chmod 700 /opt/k8s/var/lib/etcd

        ExecStartPre=-/bin/podman container kill etcd
        ExecStartPre=-/bin/podman container rm etcd
        # ExecStartPre=-/bin/podman pull quay.io/coreos/etcd:v${ETCD_VERSION}
        ExecStart= /bin/podman run --name etcd --network host --privileged \
          -e ETCD_DATA_DIR \
          -v /opt/k8s/var/lib/etcd:/var/lib/etcd \
          -v ${K8S_ROOT}/etc/kubernetes/pki:${K8S_ROOT}/etc/kubernetes/pki \
          quay.io/coreos/etcd:v${ETCD_VERSION} \
          etcd \
          --enable-v2=true \
          --name="coreos{{n}}" \
          --cert-file=${K8S_ROOT}/etc/kubernetes/pki/etcd.pem \
          --key-file=${K8S_ROOT}/etc/kubernetes/pki/etcd-key.pem \
          --trusted-ca-file=${K8S_ROOT}/etc/kubernetes/pki/etcd-ca.pem \
          --peer-cert-file=${K8S_ROOT}/etc/kubernetes/pki/etcd-peer.pem \
          --peer-key-file=${K8S_ROOT}/etc/kubernetes/pki/etcd-peer-key.pem \
          --peer-trusted-ca-file=${K8S_ROOT}/etc/kubernetes/pki/etcd-ca.pem \
          --peer-client-cert-auth \
          --client-cert-auth \
          --listen-peer-urls=https://{{IP_{{n}}}}:2380 \
          --initial-advertise-peer-urls=https://{{IP_{{n}}}}:2380 \
          --listen-client-urls=https://{{IP_{{n}}}}:2379,http://127.0.0.1:2379 \
          --advertise-client-urls=https://{{IP_{{n}}}}:2379 \
          --initial-cluster-token="mytoken" \
          --initial-cluster=${ETCD_NODES} \
          --initial-cluster-state=new \
          --auto-compaction-mode=periodic \
          --auto-compaction-retention=1 \
          --max-request-bytes=33554432 \
          --quota-backend-bytes=6442450944 \
          --heartbeat-interval=250 \
          --election-timeout=2000

        ExecStop=/bin/podman stop etcd
        ExecStopPost=/bin/podman container rm etcd

        # ExecStartPost
        # ExecReload：重启当前服务时执行的命令
        # ExecStop：停止当前服务时执行的命令
        # ExecStopPost：停止当其服务之后执行的命令
        [Install]
        WantedBy=multi-user.target

        # Alias：当前 Unit 可用于启动的别名
        # Also：当前 Unit 激活（enable）时，会被同时激活的其他 Unit
    - name: kube-apiserver.service
      enabled: true
      contents: |
        [Unit]
        Description=Kubernetes API Server
        Documentation=https://github.com/kubernetes/kubernetes
        # Requires=etcd.service
        After=network-online.target network.target
        Wants=network-online.target

        [Service]
        # Flag --experimental-encryption-provider-config has been deprecated, use --encryption-provider-config.
        # --insecure-port has been deprecated, This flag will be removed in a future version.

        Environment="K8S_ROOT=${K8S_ROOT}"

        ExecStartPre=mkdir -p /opt/k8s/var/log/kubernetes

        ExecStart=/bin/podman run \
        --name kube-apiserver \
        -v ${K8S_ROOT}:${K8S_ROOT} \
        -v /opt/k8s/var/log/kubernetes:${K8S_ROOT}/var/log/kubernetes \
        --network host \
        k8s.gcr.io/kube-apiserver:{{KUBERNETES_VERSION}} \
        kube-apiserver \
        --advertise-address={{IP_{{n}}}} \
        --default-not-ready-toleration-seconds=360 \
        --default-unreachable-toleration-seconds=360 \
        --max-mutating-requests-inflight=2000 \
        --max-requests-inflight=4000 \
        --default-watch-cache-size=200 \
        --delete-collection-workers=2 \
        --encryption-provider-config=${K8S_ROOT}/etc/kubernetes/encryption-config.yaml \
        --etcd-cafile=${K8S_ROOT}/etc/kubernetes/pki/etcd-ca.pem \
        --etcd-certfile=${K8S_ROOT}/etc/kubernetes/pki/apiserver-etcd-client.pem \
        --etcd-keyfile=${K8S_ROOT}/etc/kubernetes/pki/apiserver-etcd-client-key.pem \
        --etcd-servers=${ETCD_ENDPOINTS} \
        --bind-address={{IP_{{n}}}} \
        --secure-port=6443 \
        --tls-cert-file=${K8S_ROOT}/etc/kubernetes/pki/apiserver.pem \
        --tls-private-key-file=${K8S_ROOT}/etc/kubernetes/pki/apiserver-key.pem \
        --insecure-port=0 \
        --audit-log-maxage=15 \
        --audit-log-maxbackup=3 \
        --audit-log-maxsize=100 \
        --audit-log-truncate-enabled \
        --audit-log-path=${K8S_ROOT}/var/log/kubernetes/kube-apiserver/audit.log \
        --audit-policy-file=${K8S_ROOT}/etc/kubernetes/audit-policy.yaml \
        --profiling \
        --anonymous-auth=false \
        --client-ca-file=${K8S_ROOT}/etc/kubernetes/pki/ca.pem \
        --enable-bootstrap-token-auth \
        --requestheader-allowed-names="aggregator" \
        --requestheader-client-ca-file=${K8S_ROOT}/etc/kubernetes/pki/front-proxy-ca.pem \
        --requestheader-extra-headers-prefix="X-Remote-Extra-" \
        --requestheader-group-headers=X-Remote-Group \
        --requestheader-username-headers=X-Remote-User \
        --service-account-key-file=${K8S_ROOT}/etc/kubernetes/pki/sa.pub \
        --service-account-signing-key-file=${K8S_ROOT}/etc/kubernetes/pki/sa.key \
        --service-account-issuer=api \
        --api-audiences=api \
        --authorization-mode=Node,RBAC \
        --runtime-config=api/all=true \
        --enable-admission-plugins=NodeRestriction \
        --allow-privileged=true \
        --apiserver-count=3 \
        --event-ttl=168h \
        --kubelet-certificate-authority=${K8S_ROOT}/etc/kubernetes/pki/ca.pem \
        --kubelet-client-certificate=${K8S_ROOT}/etc/kubernetes/pki/apiserver-kubelet-client.pem \
        --kubelet-client-key=${K8S_ROOT}/etc/kubernetes/pki/apiserver-kubelet-client-key.pem \
        --kubelet-timeout=10s \
        --proxy-client-cert-file=${K8S_ROOT}/etc/kubernetes/pki/front-proxy-client.pem \
        --proxy-client-key-file=${K8S_ROOT}/etc/kubernetes/pki/front-proxy-client-key.pem \
        --service-cluster-ip-range=10.254.0.0/16 \
        --service-node-port-range="1-65535" \
        --logtostderr=true \
        --v=2

        Restart=on-failure
        RestartSec=5
        # Type=notify
        LimitNOFILE=65536
        TimeoutStartSec=0

        [Install]
        WantedBy=multi-user.target
    - name: kube-controller-manager.service
      enabled: true
      contents: |
        [Unit]
        Description=Kubernetes Controller Manager
        Documentation=https://github.com/kubernetes/kubernetes
        # Requires=kube-apiserver.service
        After=network-online.target
        Wants=network-online.target

        [Service]

        # Flag --port has been deprecated, see --secure-port instead.
        # Flag --horizontal-pod-autoscaler-use-rest-clients has been deprecated,
        # Heapster is no longer supported as a source for Horizontal Pod Autoscaler metrics.

        Environment="K8S_ROOT=${K8S_ROOT}"

        ExecStart=/bin/podman run \
        --name kube-controller-manager \
        -v ${K8S_ROOT}:${K8S_ROOT} \
        --network host \
        k8s.gcr.io/kube-controller-manager:{{KUBERNETES_VERSION}} \
        kube-controller-manager \
        --profiling \
        --cluster-name=kubernetes \
        --controllers=*,bootstrapsigner,tokencleaner \
        --kube-api-qps=1000 \
        --kube-api-burst=2000 \
        --leader-elect \
        --use-service-account-credentials \
        --concurrent-service-syncs=2 \
        --bind-address={{IP_{{n}}}} \
        --secure-port=10257 \
        --tls-cert-file=${K8S_ROOT}/etc/kubernetes/pki/kube-controller-manager.pem \
        --tls-private-key-file=${K8S_ROOT}/etc/kubernetes/pki/kube-controller-manager-key.pem \
        --port=0 \
        --authentication-kubeconfig=${K8S_ROOT}/etc/kubernetes/kube-controller-manager.kubeconfig \
        --client-ca-file=${K8S_ROOT}/etc/kubernetes/pki/ca.pem \
        --requestheader-allowed-names="" \
        --requestheader-client-ca-file=${K8S_ROOT}/etc/kubernetes/pki/ca.pem \
        --requestheader-extra-headers-prefix="X-Remote-Extra-" \
        --requestheader-group-headers=X-Remote-Group \
        --requestheader-username-headers=X-Remote-User \
        --authorization-kubeconfig=${K8S_ROOT}/etc/kubernetes/kube-controller-manager.kubeconfig \
        --cluster-signing-cert-file=${K8S_ROOT}/etc/kubernetes/pki/ca.pem \
        --cluster-signing-key-file=${K8S_ROOT}/etc/kubernetes/pki/ca-key.pem \
        --cluster-signing-duration=876000h \
        --horizontal-pod-autoscaler-sync-period=10s \
        --concurrent-deployment-syncs=10 \
        --concurrent-gc-syncs=30 \
        --node-cidr-mask-size=24 \
        --service-cluster-ip-range=10.254.0.0/16 \
        --pod-eviction-timeout=6m \
        --terminated-pod-gc-threshold=10000 \
        --root-ca-file=${K8S_ROOT}/etc/kubernetes/pki/ca.pem \
        --service-account-private-key-file=${K8S_ROOT}/etc/kubernetes/pki/sa.key \
        --kubeconfig=${K8S_ROOT}/etc/kubernetes/kube-controller-manager.kubeconfig \
        --logtostderr=true \
        --v=2

        Restart=on-failure
        RestartSec=5

        [Install]
        WantedBy=multi-user.target
    - name: kube-scheduler.service
      enabled: true
      contents: |
        [Unit]
        Description=Kubernetes Scheduler
        Documentation=https://github.com/kubernetes/kubernetes
        # Requires=kube-apiserver.service
        After=network-online.target
        Wants=network-online.target

        [Service]

        Environment="K8S_ROOT=${K8S_ROOT}"

        ExecStart=/bin/podman run --name=kube-scheduler \
        --network host \
        -v ${K8S_ROOT}:${K8S_ROOT} \
        k8s.gcr.io/kube-scheduler:{{KUBERNETES_VERSION}} \
        kube-scheduler \
        --config=${K8S_ROOT}/etc/kubernetes/kube-scheduler.config.yaml \
        --bind-address={{IP_{{n}}}} \
        --secure-port=10259 \
        --port=0 \
        --tls-cert-file=${K8S_ROOT}/etc/kubernetes/pki/kube-scheduler.pem \
        --tls-private-key-file=${K8S_ROOT}/etc/kubernetes/pki/kube-scheduler-key.pem \
        --authentication-kubeconfig=${K8S_ROOT}/etc/kubernetes/kube-scheduler.kubeconfig \
        --client-ca-file=${K8S_ROOT}/etc/kubernetes/pki/ca.pem \
        --requestheader-allowed-names="" \
        --requestheader-client-ca-file=${K8S_ROOT}/etc/kubernetes/pki/ca.pem \
        --requestheader-extra-headers-prefix="X-Remote-Extra-" \
        --requestheader-group-headers=X-Remote-Group \
        --requestheader-username-headers=X-Remote-User \
        --authorization-kubeconfig=${K8S_ROOT}/etc/kubernetes/kube-scheduler.kubeconfig \
        --logtostderr=true \
        --v=2

        Restart=on-failure
        RestartSec=5

        [Install]
        WantedBy=multi-user.target
    - name: docker-tls-tcp.socket
      enabled: true
      contents: |
        [Unit]
        Description=Docker Secured Socket for the API

        [Socket]
        # ListenStream={{IP_{{n}}}}:2376
        ListenStream=2376
        BindIPv6Only=both
        Service=docker.service

        [Install]
        WantedBy=sockets.target
    - name: kubelet.service
      enabled: true
      contents: |
        [Unit]
        Description=Kubernetes Kubelet
        Documentation=https://github.com/kubernetes/kubernetes
        # After=docker.service
        # Requires=docker.service
        After=network-online.target
        Wants=network-online.target

        [Service]
        WorkingDirectory=/home/core
        Environment="NODE_NAME=coreos{{n}}"
        # Fix me
        Environment="KUBE_APISERVER=${KUBE_APISERVER}"

        Environment="K8S_ROOT=${K8S_ROOT}"

        ExecStartPre=-/usr/bin/env swapoff -a
        ExecStartPre=-${K8S_ROOT}/bin/generate-kubelet-bootstrap-kubeconfig.sh
        ExecStartPre=-/usr/bin/env mkdir -p /opt/k8s/var/lib/kubelet
        ExecStartPre=-/usr/bin/env mkdir -p /var/lib/kubelet
        ExecStartPre=-/usr/bin/env mount --bind /opt/k8s/var/lib/kubelet /var/lib/kubelet
        ExecStartPre=-/usr/bin/env mkdir -p /opt/k8s/usr/libexec/kubernetes/kubelet-plugins/volume/exec/
        ExecStartPre=-/usr/bin/env mkdir -p /usr/libexec/kubernetes/kubelet-plugins/volume/exec/
        ExecStartPre=-/usr/bin/env mount --bind /opt/k8s/usr/libexec/kubernetes/kubelet-plugins/volume/exec/ /usr/libexec/kubernetes/kubelet-plugins/volume/exec/

        ExecStart=${K8S_ROOT}/bin/kubelet \
        --bootstrap-kubeconfig=${K8S_ROOT}/etc/kubernetes/kubelet-bootstrap.kubeconfig \
        --cert-dir=${K8S_ROOT}/etc/kubernetes/pki \
        --container-runtime=${CONTAINER_RUNTIME} \
        --container-runtime-endpoint=${CONTAINER_RUNTIME_ENDPOINT} \
        --root-dir=/opt/k8s/var/lib/kubelet \
        --kubeconfig=${K8S_ROOT}/etc/kubernetes/kubelet.kubeconfig \
        --config=${K8S_ROOT}/etc/kubernetes/kubelet.config.yaml \
        --hostname-override=coreos{{n}} \
        --volume-plugin-dir=/opt/k8s/usr/libexec/kubernetes/kubelet-plugins/volume/exec/ \
        --logtostderr=true \
        --v=2

        # cri is docker
        # --network-plugin=cni \
        # --cni-cache-dir=/opt/k8s/var/lib/cni/cache \
        # --cni-bin-dir=/opt/k8s/opt/cni/bin \
        # --cni-conf-dir=/opt/k8s/etc/cni/net.d \
        # --pod-infra-container-image=gcr.mirror/google-containers/pause:3.2 \
        # --pod-infra-container-image=registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.2 \
        # --image-pull-progress-deadline=15m \

        ExecStartPost=/usr/bin/env chown -R core:core /home/core/.kube

        ExecStopPost=-/usr/bin/env umount /var/lib/kubelet
        ExecStopPost=-/usr/bin/env umount /usr/libexec/kubernetes/kubelet-plugins/volume/exec/

        Restart=on-failure
        RestartSec=5

        [Install]
        WantedBy=multi-user.target
storage:
  files:
    - path: "/etc/hostname"
      mode: 0644
      overwrite: true
      contents:
        inline: coreos{{n}}
    - path: "/etc/hosts"
      mode: 0644
      overwrite: true
      contents:
        inline: |
          127.0.0.1 localhost
          ::1       localhost
          {{IP_1}} gcr.io k8s.gcr.io docker.khs1994.com docker.domain.com
          {{IP_1}} coreos1
          {{IP_2}} coreos2
          {{IP_3}} coreos3
          {{IP_{{n}}}} coreos{{n}}
    - path: ${K8S_ROOT}/kube-nginx/conf/kube-nginx.conf
      mode: 0644
      contents:
        inline: |
          worker_processes 1;

          events {
              worker_connections  1024;
          }

          stream {
              upstream backend {
                  hash $remote_addr consistent;
                  server {{IP_1}}:6443        max_fails=3 fail_timeout=30s;
                  server {{IP_2}}:6443        max_fails=3 fail_timeout=30s;
                  server {{IP_3}}:6443        max_fails=3 fail_timeout=30s;
              }

              server {
                  listen 127.0.0.1:18443;
                  proxy_connect_timeout 1s;
                  proxy_pass backend;
              }
          }
    - path: ${K8S_ROOT}/etc/kubernetes/kube-scheduler.config.yaml
      mode: 0644
      contents:
        inline: |
          apiVersion: kubescheduler.config.k8s.io/v1alpha1
          kind: KubeSchedulerConfiguration
          clientConnection:
            burst: 200
            kubeconfig: "${K8S_ROOT}/etc/kubernetes/kube-scheduler.kubeconfig"
            qps: 100
          enableContentionProfiling: false
          enableProfiling: true
          healthzBindAddress: {{IP_{{n}}}}:10251
          leaderElection:
            leaderElect: true
          metricsBindAddress: {{IP_{{n}}}}:10251
    - path: ${K8S_ROOT}/etc/kubernetes/kubelet.config.yaml
      mode: 0644
      contents:
        inline: |
          kind: KubeletConfiguration
          apiVersion: kubelet.config.k8s.io/v1beta1
          address: "{{IP_{{n}}}}"
          staticPodPath: ""
          syncFrequency: 1m
          fileCheckFrequency: 20s
          httpCheckFrequency: 20s
          staticPodURL: ""
          port: 10250
          readOnlyPort: 0
          rotateCertificates: true
          serverTLSBootstrap: true
          authentication:
            anonymous:
              enabled: false
            webhook:
              enabled: true
            x509:
              clientCAFile: "${K8S_ROOT}/etc/kubernetes/pki/ca.pem"
          authorization:
            mode: Webhook
          registryPullQPS: 0
          registryBurst: 20
          eventRecordQPS: 0
          eventBurst: 20
          enableDebuggingHandlers: true
          enableContentionProfiling: true
          healthzPort: 10248
          healthzBindAddress: "{{IP_{{n}}}}"
          clusterDomain: "cluster.local."
          clusterDNS:
            - "10.254.0.2"
          nodeStatusUpdateFrequency: 10s
          nodeStatusReportFrequency: 1m
          imageMinimumGCAge: 2m
          imageGCHighThresholdPercent: 85
          imageGCLowThresholdPercent: 80
          volumeStatsAggPeriod: 1m
          kubeletCgroups: ""
          systemCgroups: ""
          cgroupRoot: ""
          cgroupsPerQOS: true
          # cgroupDriver: cgroupfs
          cgroupDriver: systemd
          runtimeRequestTimeout: 10m
          hairpinMode: promiscuous-bridge
          maxPods: 220
          podCIDR: "10.244.0.0/16"
          podPidsLimit: -1
          resolvConf: /etc/resolv.conf
          maxOpenFiles: 1000000
          kubeAPIQPS: 1000
          kubeAPIBurst: 2000
          serializeImagePulls: false
          evictionHard:
            memory.available:  "100Mi"
            nodefs.available:  "10%"
            nodefs.inodesFree: "5%"
            imagefs.available: "15%"
          evictionMinimumReclaim:
            imagefs.available: "15%"
          evictionSoft: {}
          enableControllerAttachDetach: true
          failSwapOn: true
          containerLogMaxSize: 20Mi
          containerLogMaxFiles: 10
          systemReserved: {}
          kubeReserved: {}
          systemReservedCgroup: ""
          kubeReservedCgroup: ""
          enforceNodeAllocatable: ["pods"]
          # volumePluginDir: ${K8S_ROOT}/usr/libexec/kubernetes/kubelet-plugins/volume/exec/
          featureGates:
            # AllAlpha: true
            # BoundServiceAccountTokenVolume: false
    - path: ${K8S_ROOT}/etc/kubernetes/kube-proxy.config.yaml
      mode: 0644
      contents:
        inline: |
          kind: KubeProxyConfiguration
          apiVersion: kubeproxy.config.k8s.io/v1alpha1
          clientConnection:
            burst: 200
            kubeconfig: "${K8S_ROOT}/etc/kubernetes/kube-proxy.kubeconfig"
            qps: 100
          bindAddress: {{IP_{{n}}}}
          healthzBindAddress: {{IP_{{n}}}}:10256
          metricsBindAddress: {{IP_{{n}}}}:10249
          enableProfiling: true
          clusterCIDR: 10.244.0.0/16
          hostnameOverride: coreos{{n}}
          mode: "ipvs"
          portRange: ""
          iptables:
            masqueradeAll: false
          ipvs:
            scheduler: rr
            excludeCIDRs: []
    - path: ${K8S_ROOT}/bin/kubectl
      mode: 0755
      contents:
        source: http://{{SERVER_HOST}}:8080/kubernetes-release/release/{{KUBERNETES_VERSION}}-linux-amd64/kubernetes/server/bin/kubectl
    - path: /etc/NetworkManager/system-connections/enp0s3.nmconnection
      mode: 0600
      contents:
        inline: |
          [connection]
          id=enp0s3
          interface-name=enp0s3
          type=ethernet
          autoconnect=true

          [ipv4]
          method=manual
          dns=114.114.114.114;8.8.8.8;1.1.1.1
          addresses={{IP_{{n}}}}/24
          gateway=${NETWORK_GATEWAY}
          # dns-search=redhat.com
